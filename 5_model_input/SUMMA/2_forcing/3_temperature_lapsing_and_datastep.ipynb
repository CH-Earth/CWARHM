{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature lapsing and data_step\n",
    "The size discrepancy between MERIT basins and the typical coverage of ERA5 grid cells makes it appropriate to apply a temperature lapse rate. This script loops over existing basin-averaged forcing files and applies a lapse rate to the `airtemp` variable. Lapse arte is determined based on the average elevation difference between the basin shape and the ERA5 grid cell(s) that cover the basin.\n",
    "\n",
    "In addition, this script adds the `data_step` variable to each forcing file, which SUMMA needs to know the time resolution of the forcing inputs.\n",
    "\n",
    "#### Environmental Lapse Rate\n",
    "The temperature lapse rate is assumed to have a constant value of `0.0065` `[K m-1]` (Wallace & Hobbs, 2006, p. 421).\n",
    "\n",
    "_Wallace, J., and P. Hobbs (2006), Atmospheric Science: An Introductory Survey, 483 pp., Academic Press, Burlington, Mass_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control file handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy access to control file folder\n",
    "controlFolder = Path('../../../0_control_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the name of the 'active' file in a variable\n",
    "controlFile = 'control_active.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract a given setting from the control file\n",
    "def read_from_control( file, setting ):\n",
    "    \n",
    "    # Open 'control_active.txt' and ...\n",
    "    with open(file) as contents:\n",
    "        for line in contents:\n",
    "            \n",
    "            # ... find the line with the requested setting\n",
    "            if setting in line:\n",
    "                break\n",
    "    \n",
    "    # Extract the setting's value\n",
    "    substring = line.split('|',1)[1]      # Remove the setting's name (split into 2 based on '|', keep only 2nd part)\n",
    "    substring = substring.split('#',1)[0] # Remove comments, does nothing if no '#' is found\n",
    "    substring = substring.strip()         # Remove leading and trailing whitespace, tabs, newlines\n",
    "       \n",
    "    # Return this value    \n",
    "    return substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to specify a default path\n",
    "def make_default_path(suffix):\n",
    "    \n",
    "    # Get the root path\n",
    "    rootPath = Path( read_from_control(controlFolder/controlFile,'root_path') )\n",
    "    \n",
    "    # Get the domain folder\n",
    "    domainName = read_from_control(controlFolder/controlFile,'domain_name')\n",
    "    domainFolder = 'domain_' + domainName\n",
    "    \n",
    "    # Specify the forcing path\n",
    "    defaultPath = rootPath / domainFolder / suffix\n",
    "    \n",
    "    return defaultPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find location of intersection file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersected shapefile path. Name is set by CANDEX as [prefix]_intersected_shapefile.shp\n",
    "intersect_path = read_from_control(controlFolder/controlFile,'intersect_forcing_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify default path if needed\n",
    "if intersect_path == 'default':\n",
    "    intersect_path = make_default_path('shapefiles/catchment_intersection/with_forcing') # outputs a Path()\n",
    "else:\n",
    "    intersect_path = Path(intersect_path) # make sure a user-specified path is a Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the file name\n",
    "domain = read_from_control(controlFolder/controlFile,'domain_name')\n",
    "intersect_name = domain + '_intersected_shapefile.csv' # can also be .shp, but using the .csv is easier on memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find where the CANDEX-prepared forcing files are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcing files as produced by CANDEX\n",
    "forcing_candex_path = read_from_control(controlFolder/controlFile,'forcing_basin_avg_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify default path if needed\n",
    "if forcing_candex_path == 'default':\n",
    "    forcing_candex_path = make_default_path('forcing/3_basin_averaged_data') # outputs a Path()\n",
    "else:\n",
    "    forcing_candex_path = Path(forcing_candex_path) # make sure a user-specified path is a Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the files\n",
    "_,_,forcing_files = next(os.walk(forcing_candex_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the time step size of the forcing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value in control file\n",
    "data_step = read_from_control(controlFolder/controlFile,'forcing_time_step_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to int\n",
    "data_step = int(data_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find where the final forcing needs to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location for SUMMA-ready files\n",
    "forcing_summa_path = read_from_control(controlFolder/controlFile,'forcing_summa_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify default path if needed\n",
    "if forcing_summa_path == 'default':\n",
    "    forcing_summa_path = make_default_path('forcing/4_SUMMA_input') # outputs a Path()\n",
    "else:\n",
    "    forcing_summa_path = Path(forcing_summa_path) # make sure a user-specified path is a Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the folder if it doesn't exist\n",
    "forcing_summa_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the area-weighted lapse value for each basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the intersection file\n",
    "topo_data = pd.read_csv(intersect_path/intersect_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find hruId name in user's shapefile\n",
    "hru_ID_name = read_from_control(controlFolder/controlFile,'catchment_shp_hruid')\n",
    "gru_ID_name = read_from_control(controlFolder/controlFile,'catchment_shp_gruid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the column names\n",
    "# Note that column names are truncated at 10 characters in the ESRI shapefile, but NOT in the .csv we use here\n",
    "gru_ID         = 'S_1_' + gru_ID_name # CANDEX prefix + user's hruId name\n",
    "hru_ID         = 'S_1_' + hru_ID_name # CANDEX prefix + user's hruId name\n",
    "forcing_ID     = 'S_2_ID'             # fixed name assigned by CANDEX\n",
    "catchment_elev = 'S_1_elev_mean'      # CANDEX prefix + name used in catchment+DEM intersection step\n",
    "forcing_elev   = 'S_2_elev_m'         # CANDEX prefix + name used in ERA5 shapefile generation\n",
    "weights        = 'weight'             # CANDEX feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lapse rate\n",
    "lapse_rate = 0.0065 # [K m-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted lapse values for each HRU \n",
    "# Note that these lapse values need to be SUBTRACTED from ERA5 temperature data\n",
    "lapse_values = topo_data[weights] * lapse_rate * ( topo_data[forcing_elev] - topo_data[catchment_elev]) # [K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lapse values to dataframe\n",
    "topo_data['lapse_values'] = lapse_values # [K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the total lapse value per basin; i.e. sum the individual contributions of each HRU+ERA5-grid overlapping part\n",
    "lapse_values = topo_data.groupby([gru_ID,hru_ID]).lapse_values.sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_1_GRU_ID</th>\n",
       "      <th>lapse_values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_1_HRU_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71028597</td>\n",
       "      <td>-0.530803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71028609</td>\n",
       "      <td>-0.413910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71028676</td>\n",
       "      <td>-0.863720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71028700</td>\n",
       "      <td>-0.666452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71028740</td>\n",
       "      <td>-1.204602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>71030774</td>\n",
       "      <td>4.228418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>71031120</td>\n",
       "      <td>4.034569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>71031359</td>\n",
       "      <td>3.808350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>71031506</td>\n",
       "      <td>4.732154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>71028585</td>\n",
       "      <td>3.967619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            S_1_GRU_ID  lapse_values\n",
       "S_1_HRU_ID                          \n",
       "1             71028597     -0.530803\n",
       "2             71028609     -0.413910\n",
       "3             71028676     -0.863720\n",
       "4             71028700     -0.666452\n",
       "5             71028740     -1.204602\n",
       "...                ...           ...\n",
       "114           71030774      4.228418\n",
       "115           71031120      4.034569\n",
       "116           71031359      3.808350\n",
       "117           71031506      4.732154\n",
       "118           71028585      3.967619\n",
       "\n",
       "[118 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort and set hruID as the index variable\n",
    "lapse_values = lapse_values.sort_values(hru_ID).set_index(hru_ID)\n",
    "lapse_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the main file\n",
    "del topo_data # hopefully this saves some RAM but this is apparently not so straightforward in Python.. Can't hurt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop over forcing files; apply lapse rates and add data_step variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on BowAtBanff_remapped_1979-01-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-02-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-03-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-04-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-05-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-06-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-07-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-08-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-09-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-10-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-11-01-00-00-00.nc\n",
      "Starting on BowAtBanff_remapped_1979-12-01-00-00-00.nc\n"
     ]
    }
   ],
   "source": [
    "# Initiate the loop\n",
    "for file in forcing_files:\n",
    "    \n",
    "    # Progress\n",
    "    print('Starting on ' + file)\n",
    "    \n",
    "    # load the data\n",
    "    with xr.open_dataset(forcing_candex_path / file) as dat:\n",
    "    \n",
    "        # --- Temperature lapse rates\n",
    "        # Find the lapse rates by matching the HRU order in the forcing file with that in 'lapse_values'\n",
    "        lapse_values_sorted = lapse_values['lapse_values'].loc[dat['hruId'].values]\n",
    "    \n",
    "        # Make a data array of size (nTime,nHru) \n",
    "        subtractThis = xr.DataArray(np.tile(lapse_values_sorted.values, (len(dat['time']),1)), dims=('time','hru')) \n",
    "    \n",
    "        # Subtract lapse values from existing temperature data\n",
    "        dat['airtemp'] = dat['airtemp'] - subtractThis\n",
    "    \n",
    "        # --- Time step specification \n",
    "        dat['data_step'] = data_step\n",
    "        dat.data_step.attrs['long_name'] = 'data step length in seconds'\n",
    "        dat.data_step.attrs['units'] = 's'\n",
    "    \n",
    "        # --- Save to file in new location\n",
    "        dat.to_netcdf(forcing_summa_path/file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code provenance\n",
    "Generates a basic log file in the domain folder and copies the control file and itself there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the log path and file name\n",
    "logPath = forcing_summa_path\n",
    "log_suffix = '_temperature_lapse_and_datastep.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log folder\n",
    "logFolder = '_workflow_log'\n",
    "Path( logPath / logFolder ).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy this script\n",
    "thisFile = '3_temperature_lapsing_and_datastep.ipynb'\n",
    "copyfile(thisFile, logPath / logFolder / thisFile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date and time\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log file \n",
    "logFile = now.strftime('%Y%m%d') + log_suffix\n",
    "with open( logPath / logFolder / logFile, 'w') as file:\n",
    "    \n",
    "    lines = ['Log generated by ' + thisFile + ' on ' + now.strftime('%Y/%m/%d %H:%M:%S') + '\\n',\n",
    "             'Applied temperature lapse rate to forcing data and added data_step variable.']\n",
    "    for txt in lines:\n",
    "        file.write(txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geospatialTools_qgis_candex]",
   "language": "python",
   "name": "conda-env-geospatialTools_qgis_candex-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
