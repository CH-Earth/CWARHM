{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine separate surface and pressure level downloads\n",
    "Creates a single monthly `.nc` file with SUMMA-ready variables for further processing. Combines ERA5's `u` and `v` wind components into a single directionless wind vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "from datetime import datetime\n",
    "from shutil import copyfile\n",
    "from pathlib import Path\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control file handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy access to control file folder\n",
    "controlFolder = Path('../../0_control_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the name of the 'active' file in a variable\n",
    "controlFile = 'control_active.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract a given setting from the control file\n",
    "def read_from_control( file, setting ):\n",
    "    \n",
    "    # Open 'control_active.txt' and ...\n",
    "    with open(file) as contents:\n",
    "        for line in contents:\n",
    "            \n",
    "            # ... find the line with the requested setting\n",
    "            if setting in line and not line.startswith('#'):\n",
    "                break\n",
    "    \n",
    "    # Extract the setting's value\n",
    "    substring = line.split('|',1)[1]      # Remove the setting's name (split into 2 based on '|', keep only 2nd part)\n",
    "    substring = substring.split('#',1)[0] # Remove comments, does nothing if no '#' is found\n",
    "    substring = substring.strip()         # Remove leading and trailing whitespace, tabs, newlines\n",
    "       \n",
    "    # Return this value    \n",
    "    return substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to specify a default path\n",
    "def make_default_path(suffix):\n",
    "    \n",
    "    # Get the root path\n",
    "    rootPath = Path( read_from_control(controlFolder/controlFile,'root_path') )\n",
    "    \n",
    "    # Get the domain folder\n",
    "    domainName = read_from_control(controlFolder/controlFile,'domain_name')\n",
    "    domainFolder = 'domain_' + domainName\n",
    "    \n",
    "    # Specify the forcing path\n",
    "    defaultPath = rootPath / domainFolder / suffix\n",
    "    \n",
    "    return defaultPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find source and destination paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the path where the raw forcing is\n",
    "# Immediately store as a 'Path' to avoid issues with '/' and '\\' on different operating systems\n",
    "forcingPath = read_from_control(controlFolder/controlFile,'forcing_raw_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the path where the merged forcing needs to go\n",
    "mergePath = read_from_control(controlFolder/controlFile,'forcing_merged_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the default paths if required\n",
    "if forcingPath == 'default':\n",
    "    forcingPath = make_default_path('forcing/1_ERA5_raw_data')\n",
    "else: \n",
    "    forcingPath = Path(forcingPath) # ensure Path() object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mergePath == 'default':\n",
    "    mergePath = make_default_path('forcing/2_merged_data')\n",
    "else: \n",
    "    mergePath = Path(mergePath) # ensure Path() object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the merge folder if it doesn't exist\n",
    "mergePath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find years to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which years were downloaded\n",
    "years = read_from_control(controlFolder/controlFile,'forcing_raw_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the string into 2 integers\n",
    "years = years.split(',')\n",
    "years = [int(year) for year in years]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished merging ERA5_surface_197901.nc and ERA5_pressureLevel137_197901.nc into ERA5_merged_197901.nc\n",
      "Finished merging ERA5_surface_197902.nc and ERA5_pressureLevel137_197902.nc into ERA5_merged_197902.nc\n",
      "Finished merging ERA5_surface_197903.nc and ERA5_pressureLevel137_197903.nc into ERA5_merged_197903.nc\n",
      "Finished merging ERA5_surface_197904.nc and ERA5_pressureLevel137_197904.nc into ERA5_merged_197904.nc\n",
      "Finished merging ERA5_surface_197905.nc and ERA5_pressureLevel137_197905.nc into ERA5_merged_197905.nc\n",
      "Finished merging ERA5_surface_197906.nc and ERA5_pressureLevel137_197906.nc into ERA5_merged_197906.nc\n",
      "Finished merging ERA5_surface_197907.nc and ERA5_pressureLevel137_197907.nc into ERA5_merged_197907.nc\n",
      "Finished merging ERA5_surface_197908.nc and ERA5_pressureLevel137_197908.nc into ERA5_merged_197908.nc\n",
      "Finished merging ERA5_surface_197909.nc and ERA5_pressureLevel137_197909.nc into ERA5_merged_197909.nc\n",
      "Finished merging ERA5_surface_197910.nc and ERA5_pressureLevel137_197910.nc into ERA5_merged_197910.nc\n",
      "Finished merging ERA5_surface_197911.nc and ERA5_pressureLevel137_197911.nc into ERA5_merged_197911.nc\n",
      "Finished merging ERA5_surface_197912.nc and ERA5_pressureLevel137_197912.nc into ERA5_merged_197912.nc\n"
     ]
    }
   ],
   "source": [
    "# Loop through all years and months\n",
    "for year in range(years[0],years[1]+1):\n",
    "    for month in range (1,13):\n",
    "\n",
    "        # Define file names \n",
    "        data_pres = 'ERA5_pressureLevel137_' + str(year) + str(month).zfill(2) + '.nc'\n",
    "        data_surf = 'ERA5_surface_' + str(year) + str(month).zfill(2) + '.nc'\n",
    "        data_dest = 'ERA5_merged_' + str(year) + str(month).zfill(2) + '.nc'\n",
    "\n",
    "        # Step 1: convert lat/lon in the pressure level file to range [-180,180], [-90,90]\n",
    "        # Extract the variables we need for the similarity check in a way that closes the files implicitly\n",
    "        with nc4.Dataset(forcingPath / data_pres) as src1, nc4.Dataset(forcingPath / data_surf) as src2:\n",
    "            pres_lat = src1.variables['latitude'][:]\n",
    "            pres_lon = src1.variables['longitude'][:]\n",
    "            pres_time = src1.variables['time'][:]\n",
    "            surf_lat = src2.variables['latitude'][:]\n",
    "            surf_lon = src2.variables['longitude'][:]\n",
    "            surf_time = src2.variables['time'][:]\n",
    "\n",
    "        # Update the pressure level coordinates\n",
    "        pres_lat[pres_lat > 90] = pres_lat[pres_lat > 90] - 180\n",
    "        pres_lon[pres_lon > 180] = pres_lon[pres_lon > 180] - 360\n",
    "\n",
    "        # Step 2: check that coordinates and time are the same between the both files\n",
    "        # Compare dimensions (lat, long, time)\n",
    "        flag_loc_and_time_same = [all(pres_lat == surf_lat), all(pres_lon == surf_lon), all(pres_time == surf_time)]\n",
    "\n",
    "        # Check that they are all the same\n",
    "        if not all(flag_loc_and_time_same):\n",
    "            err_txt = 'Dimension mismatch while merging ' + data_pres + ' and ' + data_surf + '. Check latitude, longitude and time dimensions in both files. Continuing with next files.'\n",
    "            print(err_txt)\n",
    "            continue\n",
    "\n",
    "        # Step 3: combine everything into a single .nc file\n",
    "        # Order of writing things:\n",
    "        # - Meta attributes from both source files\n",
    "        # - Dimensions (lat, lon, time)\n",
    "        # - Variables: long, lat and time\n",
    "        # - Variables: forcing at surface\n",
    "        # - Variables: forcing at pressure level 137\n",
    "\n",
    "        # Define the variables we want to transfer\n",
    "        variables_surf_transfer = ['longitude','latitude','time']\n",
    "        variables_surf_convert = ['sp','mtpr','msdwswrf','msdwlwrf']\n",
    "        variables_pres_convert = ['t','q']\n",
    "        attr_names_expected = ['scale_factor','add_offset','_FillValue','missing_value','units','long_name','standard_name'] # these are the attributes we think each .nc variable has             \n",
    "        loop_attr_copy_these = ['units','long_name','standard_name'] # we will define new values for _FillValue and missing_value when writing the .nc variables' attributes\n",
    "\n",
    "        # Open the destination file and transfer information\n",
    "        with nc4.Dataset(forcingPath / data_pres) as src1, nc4.Dataset(forcingPath / data_surf) as src2, \\\n",
    "             nc4.Dataset(mergePath / data_dest, \"w\") as dest: \n",
    "    \n",
    "            # === Some general attributes\n",
    "            dest.setncattr('History','Created ' + time.ctime(time.time()))\n",
    "            dest.setncattr('Language','Written using Python')\n",
    "            dest.setncattr('Reason','(1) ERA5 surface and pressure files need to be combined into a single file (2) Wind speed U and V components need to be combined into a single vector (3) Forcing variables need to be given to SUMMA without scale and offset')\n",
    "    \n",
    "            # === Meta attributes from both sources\n",
    "            for name in src1.ncattrs():\n",
    "                dest.setncattr(name + ' (pressure level (10m) data)', src1.getncattr(name))\n",
    "            for name in src2.ncattrs():\n",
    "                dest.setncattr(name + ' (surface level data)', src1.getncattr(name))\n",
    "    \n",
    "            # === Dimensions: latitude, longitude, time\n",
    "            # NOTE: we can use the lat/lon from the surface file (src2), because those are already in proper units. If there is a mismatch between surface and pressure we shouldn't have reached this point at all due to the check above\n",
    "            for name, dimension in src2.dimensions.items():\n",
    "                if dimension.isunlimited():\n",
    "                    dest.createDimension( name, None)\n",
    "                else:\n",
    "                    dest.createDimension( name, len(dimension))\n",
    "    \n",
    "            # === Get the surface level generic variables (lat, lon, time)\n",
    "            for name, variable in src2.variables.items():\n",
    "        \n",
    "                # Transfer lat, long and time variables because these don't have scaling factors\n",
    "                if name in variables_surf_transfer:\n",
    "                    dest.createVariable(name, variable.datatype, variable.dimensions, fill_value = -999)\n",
    "                    dest[name].setncatts(src1[name].__dict__)\n",
    "                    dest.variables[name][:] = src2.variables[name][:]\n",
    "            \n",
    "            # === For the forcing variables, we need to:\n",
    "            # 1. Extract them (this automatically applies scaling and offset with nc4) and apply non-negativity constraints\n",
    "            # 2. Create a .nc variable with the right SUMMA name and file type\n",
    "            # 3. Put all data into the new .nc file\n",
    "    \n",
    "            # ===  Transfer the surface level data first, for no particular reason\n",
    "            # This should contain surface pressure (sp), downward longwave (msdwlwrf), downward shortwave (msdwswrf) and precipitation (mtpr)\n",
    "            for name, variable in src2.variables.items():\n",
    "    \n",
    "                # Check that we are only using the names we expect, and thus the names for which we have the required code ready\n",
    "                if name in variables_surf_convert:\n",
    "            \n",
    "                    # 0. Reset the dictionary that we keep attribute values in\n",
    "                    loop_attr_source_values = {name: 'n/a' for name in attr_names_expected}\n",
    "            \n",
    "                    # 1a. Get the values of this variable from the source (this automatically applies scaling and offset)\n",
    "                    loop_val = variable[:]\n",
    "\n",
    "                    # 1b. Apply non-negativity constraint. This is intended to remove very small negative data values that sometimes occur\n",
    "                    loop_val[loop_val < 0] = 0\n",
    "            \n",
    "                    # 1c. Get the attributes for this variable from source\n",
    "                    for attrname in variable.ncattrs():\n",
    "                        loop_attr_source_values[attrname] = variable.getncattr(attrname)\n",
    "            \n",
    "                    # 2a. Find what this ERA5 variable should be called in SUMMA\n",
    "                    if name == 'sp':\n",
    "                        name_summa = 'airpres'\n",
    "                    elif name == 'msdwlwrf':\n",
    "                        name_summa = 'LWRadAtm'\n",
    "                    elif name == 'msdwswrf':\n",
    "                        name_summa = 'SWRadAtm'\n",
    "                    elif name == 'mtpr':\n",
    "                        name_summa = 'pptrate'            \n",
    "                    else:\n",
    "                        name_summa = 'n/a/' # no name so we don't start overwriting data if a new name is not defined for some reason\n",
    "            \n",
    "                    # 2b. Create the .nc variable with the proper SUMMA name\n",
    "                    # Inputs: variable name as needed by SUMMA; data type: 'float'; dimensions; no need for fill value, because thevariable gets populated in this same script\n",
    "                    dest.createVariable(name_summa, 'f4', ('time','latitude','longitude'), fill_value = False)\n",
    "            \n",
    "                    # 3a. Select the attributes we want to copy for this variable, based on the dictionary defined before the loop starts\n",
    "                    loop_attr_copy_values = {use_this: loop_attr_source_values[use_this] for use_this in loop_attr_copy_these}\n",
    "            \n",
    "                    # 3b. Copy the attributes FIRST, so we don't run into any scaling/offset issues\n",
    "                    dest[name_summa].setncattr('missing_value',-999)\n",
    "                    dest[name_summa].setncatts(loop_attr_copy_values)\n",
    "            \n",
    "                    # 3c. Copy the data SECOND\n",
    "                    dest[name_summa][:] = loop_val\n",
    "            \n",
    "            # === Transfer the pressure level variables next, using the same procedure as above\n",
    "            for name, variable in src1.variables.items():\n",
    "                if name in variables_pres_convert:\n",
    "            \n",
    "                    # 0. Reset the dictionary that we keep attribute values in\n",
    "                    loop_attr_source_values = {name: 'n/a' for name in attr_names_expected}\n",
    "            \n",
    "                    # 1a. Get the values of this variable from the source (this automatically applies scaling and offset)\n",
    "                    loop_val = variable[:] \n",
    "            \n",
    "                    # 1b. Get the attributes for this variable from source\n",
    "                    for attrname in variable.ncattrs():\n",
    "                        loop_attr_source_values[attrname] = variable.getncattr(attrname)\n",
    "            \n",
    "                    # 2a. Find what this ERA5 variable should be called in SUMMA\n",
    "                    if name == 't':\n",
    "                        name_summa = 'airtemp'\n",
    "                    elif name == 'q':\n",
    "                        name_summa = 'spechum'\n",
    "                    elif name == 'u':\n",
    "                        name_summa = 'n/a/' # we shouldn't reach this part of the code, because 'u' is not specified in 'variables_pres_convert'\n",
    "                    elif name == 'v':\n",
    "                        name_summa = 'n/a' # as with 'u', because both are needed to calculate total wind speed first\n",
    "                    else:\n",
    "                        name_summa = 'n/a/' # no name so we don't start overwriting data if a new name is not defined for some reason\n",
    "            \n",
    "                    # 2b. Create the .nc variable with the proper SUMMA name\n",
    "                    # Inputs: variable name as needed by SUMMA; data type: 'float'; dimensions; no need for fill value, because thevariable gets populated in this same script\n",
    "                    dest.createVariable(name_summa, 'f4', ('time','latitude','longitude'), fill_value = False)\n",
    "            \n",
    "                    # 3a. Select the attributes we want to copy for this variable, based on the dictionary defined before the loop starts\n",
    "                    loop_attr_copy_values = {use_this: loop_attr_source_values[use_this] for use_this in loop_attr_copy_these}\n",
    "            \n",
    "                    # 3b. Copy the attributes FIRST, so we don't run into any scaling/offset issues\n",
    "                    dest[name_summa].setncattr('missing_value',-999)\n",
    "                    dest[name_summa].setncatts(loop_attr_copy_values)\n",
    "            \n",
    "                    # 3c. Copy the data SECOND\n",
    "                    dest[name_summa][:] = loop_val\n",
    "            \n",
    "            # === Calculate combined wind speed and store\n",
    "            # 1a. Get the values of this variable from the source (this automatically applies scaling and offset)\n",
    "            pres_u = src1.variables['u'][:]\n",
    "            pres_v = src1.variables['v'][:]\n",
    "    \n",
    "            # 1b. Create the variable attribute 'units' from the source data. This lets us check if the source units match (they should match)\n",
    "            unit_u = src1.variables['u'].getncattr('units')\n",
    "            unit_v = src1.variables['v'].getncattr('units')\n",
    "            unit_w = '(({})**2 + ({})**2)**0.5'.format(unit_u,unit_v) \n",
    "    \n",
    "            # 2a. Set the summa_name\n",
    "            name_summa = 'windspd'\n",
    "    \n",
    "            # 2b. Create the .nc variable with the proper SUMMA name\n",
    "            # Inputs: variable name as needed by SUMMA; data type: 'float'; dimensions; no need for fill value, because thevariable gets populated in this same script\n",
    "            dest.createVariable(name_summa,'f4',('time','latitude','longitude'),fill_value = False)\n",
    "    \n",
    "            # 3a. Set the attributes FIRST, so we don't run into any scaling/offset issues\n",
    "            dest[name_summa].setncattr('missing_value',-999)\n",
    "            dest[name_summa].setncattr('units',unit_w)\n",
    "            dest[name_summa].setncattr('long_name','wind speed at the measurement height, computed from ERA5 U and V-components')\n",
    "            dest[name_summa].setncattr('standard_name','wind_speed')\n",
    "    \n",
    "            # 3b. Copy the data SECOND\n",
    "            # Creating a new variable first and writing to .nc later seems faster than directly writing to .nc\n",
    "            pres_w = ((pres_u**2)+(pres_v**2))**0.5\n",
    "            dest[name_summa][:] = pres_w\n",
    "    \n",
    "        print('Finished merging {} and {} into {}'.format(data_surf,data_pres,data_dest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code provenance\n",
    "Generates a basic log file in the domain folder and copies the control file and itself there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log folder\n",
    "logFolder = '_workflow_log'\n",
    "Path( mergePath / logFolder ).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy this script\n",
    "thisFile = 'ERA5_surface_and_pressure_level_combiner.ipynb'\n",
    "copyfile(thisFile, mergePath / logFolder / thisFile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date and time\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log file \n",
    "logFile = now.strftime('%Y%m%d') + '_merge_forcing_log.txt'\n",
    "with open( mergePath / logFolder / logFile, 'w') as file:\n",
    "    \n",
    "    lines = ['Log generated by ' + thisFile + ' on ' + now.strftime('%Y/%m/%d %H:%M:%S') + '\\n',\n",
    "             'Merged ERA5 pressure and surface level data into single files.']\n",
    "    for txt in lines:\n",
    "        file.write(txt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summa-env",
   "language": "python",
   "name": "summa-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
